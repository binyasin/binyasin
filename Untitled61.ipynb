{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPkyfYNtIb8ME5xsbm/K9RM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/binyasin/binyasin/blob/main/Untitled61.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq openai-agents  \"openai-agents[litellm]\""
      ],
      "metadata": {
        "id": "WvwwlATJbkZo"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations"
      ],
      "metadata": {
        "id": "eXZXR37AacH-"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio"
      ],
      "metadata": {
        "id": "5rFNX5eiae6-"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, Runner, function_tool, set_tracing_disabled\n",
        "from agents.extensions.models.litellm_model import LitellmModel\n",
        "from google.colab import userdata\n",
        "import os # Import the os module\n",
        "\n",
        "set_tracing_disabled(disabled=True)\n",
        "\n",
        "MODEL = 'gemini/gemini-2.0-flash'\n",
        "# Get the API key from the environment variable\n",
        "OPEN_API_KEY2 = os.environ.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "#If OPENAI_API_KEY environment variable is not set, fall back to userdata\n",
        "if OPEN_API_KEY2 is None:\n",
        "    OPEN_API_KEY2 = userdata.get(\"OPEN_API_KEY2\")\n",
        "\n",
        "\n",
        "@function_tool\n",
        "def get_weather(city: str)->str:\n",
        "    print(f\"[debug] getting weather for {city}\")\n",
        "    return f\"The weather in {city} is sunny.\"\n",
        "\n",
        "\n",
        "agent2 = Agent(\n",
        "    name=\"K.E assistant\",\n",
        "    instructions=\"You will provide About K.E.\",\n",
        "    handoff_description=\"K.E expert.\",\n",
        "    model=LitellmModel(model=MODEL, api_key=OPEN_API_KEY2), # Pass the API key here\n",
        ")\n",
        "\n",
        "agent1 = Agent(\n",
        "    name=\"Assistant\",\n",
        "    instructions=\"You only respond in haikus. and handoff K.E relevant thing to K.E assistant\",\n",
        "    model=LitellmModel(model=MODEL, api_key=OPEN_API_KEY2), # Pass the API key here\n",
        "    handoffs=[agent2]\n",
        ")\n",
        "\n",
        "result = await Runner.run(agent1, \"which Advancement providing by K.E?\")\n",
        "print(result.final_output)\n",
        "print(result.last_agent)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIZHhnEfagaM",
        "outputId": "6587712e-b92f-4675-b708-40066f73c15b"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! I am K.E. Assistant, ready to provide information about K.E. \n",
            "\n",
            "To answer your question about advancements provided by K.E., I need a little more context. \"K.E.\" could refer to a variety of things. To give you the most accurate answer, could you please clarify what K.E. you are asking about? For example, are you interested in:\n",
            "\n",
            "*   **A specific company or organization (e.g., K.E. Corporation, K.E. Foundation)?** If so, please provide the full name or a brief description.\n",
            "*   **A particular field or area of study (e.g., Knowledge Engineering)?**\n",
            "*   **Something else entirely?**\n",
            "\n",
            "Once I have a better understanding of which K.E. you're interested in, I can provide you with information about its advancements.\n",
            "\n",
            "Agent(name='K.E assistant', instructions='You will provide About K.E.', handoff_description='K.E expert.', handoffs=[], model=<agents.extensions.models.litellm_model.LitellmModel object at 0x7b4e28abfc90>, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True)\n"
          ]
        }
      ]
    }
  ]
}